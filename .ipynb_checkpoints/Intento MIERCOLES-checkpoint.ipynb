{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the INIT\n",
      "\n",
      "Esto es el kickstart\n",
      "\n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[]]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 1 \n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[], []]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 2 \n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[], [], []]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 3 \n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[], [], [], []]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 4 \n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[], [], [], [], []]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 5 \n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[], [], [], [], [], []]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 6 \n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[], [], [], [], [], [], []]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 7 \n",
      "\n",
      "Running the request\n",
      "Esto es el quotes parser\n",
      "Esto es la funcion Output_results\n",
      "\n",
      "\n",
      "[[], [], [], [], [], [], [], []]\n",
      "\n",
      "\n",
      "Esto es despues de r\n",
      "\n",
      "Scrapped the page number 8 \n",
      "\n",
      "Esto es el final del kickstart\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests, sys, time, random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "name_list=[]\n",
    "price_list =[]\n",
    "url_list=[]\n",
    "name_final=[]\n",
    "\n",
    "\n",
    "class Euroelect:\n",
    "   \n",
    "    def __init__(self, url_pattern_1, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        print(\"Running the INIT\\n\")\n",
    "        self.url_pattern = url_pattern_1\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "        \n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "\n",
    "    def output_results(self, r):\n",
    "        \n",
    "        #This is the suggested code to export the code to Pandas\n",
    "        \n",
    "        if len(name_list)==8:\n",
    "            name_final = [y for x in name_list for y in x]\n",
    "            #print(name_final,\"\\n\\n\")\n",
    "            price_final= [y for x in price_list for y in x]\n",
    "            #print(price_final,\"\\n\\n\")\n",
    "            url_final= [y for x in url_list for y in x]\n",
    "            df = pd.DataFrame(list(zip(name_final,price_final,url_final)), columns=['Articulo', 'Precio', 'URL Link'])\n",
    "            print(df)\n",
    "            data = df.to_csv('/Users/macbookair7/Documents/Irving/Profesional/DATA/Entregables/Proyecto/Proyecto_web_scrapping/Datos_Cravioto.csv', index=False)\n",
    "        \n",
    "    def kickstart(self):\n",
    "\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            print(\"Scrapped the page number\",i,\"\\n\")\n",
    "            time.sleep(random.randint(0,5))\n",
    "\n",
    "URL_PATTERN_1 = 'https://casacraviotoeshop.com/productos.html?p=%s'\n",
    "PAGES_TO_SCRAPE = 8\n",
    "\n",
    "def quotes_parser_1(content):\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    product_name = soup.select('a.product-item-link')\n",
    "    product_price = soup.select('span.price')\n",
    "    product_url= soup.select('img.product-image-photo')\n",
    "    \n",
    "    #I had issues trying to get the images URL. I tried as it is write, but when I print the lists, i find out that they\n",
    "    #are empty. Feedback is welcome (please hahaha).\n",
    "    \n",
    "    name_selection = [e.get_text().strip() for e in product_name]\n",
    "    price_selection = [e.get_text().strip() for e in product_price]\n",
    "    url_selection = [e.get_text() for e in product_url]\n",
    "    name_list.append(name_selection)\n",
    "    price_list.append(price_selection)\n",
    "    url_list.append(url_selection)\n",
    "   \n",
    "    return name_selection, price_selection\n",
    "\n",
    "\n",
    "project = Euroelect(URL_PATTERN_1, PAGES_TO_SCRAPE, content_parser=quotes_parser_1)\n",
    "\n",
    "project.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
